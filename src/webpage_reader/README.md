# Web Reader
* This is a simple RAG stack application that reads a webpage

### Steps
* Read the webpage using langchain and openai
* Split the retrieved data
* Convert the data to vectors using embeddings
* Use the vectors to generate a summary of the webpage or query the data


#### Import Modules:
* Bring in necessary configurations, utility functions, and constants required for the application.
* Include libraries related to LangChain, such as text splitters, document loaders, LLM models, embeddings, and vector store tools.

#### Set Configuration:
* Use a configuration object to initialize and set environment variables. Confirm whether the environment is set up correctly.

#### Class Definition:
* Create a class that encapsulates all the logic for a Retrieval-Augmented Generation (RAG) application.

#### Webpage Content Loading:
* Use a loader to fetch the webpage content from the specified URL.

#### Split Text into Chunks:
* Divide the webpage content into smaller, manageable pieces. 
* Each chunk has a specified size and overlaps with the previous one to preserve context.

#### Generate Embeddings:
* Convert the text chunks into embeddings using the selected OpenAI embeddings model.

#### Create a Vector Store:
* Store the embeddings in a database (FAISS) for efficient retrieval.
* Configure the database to function as a retriever that can fetch relevant text based on queries.

#### Query and Retrieval Pipeline:
* Define a method to:
  * Prepare a prompt for querying the retriever. 
  * Combine document chunks to construct a coherent response using `create_stuff_documents_chain`. 
    * The `create_stuff_documents_chain` function is used to combine the retrieved document chunks into a unified response. 
    * It connects the chunks meaningfully and ensures coherence before passing them to the language model for further processing.
  * Build a pipeline to integrate document retrieval with LLM-generated answers `create_retrieval_chain`.
    * The `create_retrieval_chain` function combines the retriever and the chain created by create_stuff_documents_chain. 
    * This pipeline:
      * Retrieves relevant document chunks using the retriever. 
      * Processes the chunks with the LLM and the given prompt to generate the final answer.

* Answer Questions:
  * Run the retrieval pipeline to process a question and return the relevant answer from the webpage content.

#### Execution:
* Create an instance of the class. 
* Execute the program by running the retrieval pipeline with a predefined question. 
* Display the answer generated by the system.

